{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3582051",
   "metadata": {},
   "source": [
    "## Creating image patches from hyperspectral images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd834d8e",
   "metadata": {},
   "source": [
    "Due to how large the VIS-NIR hyperspectral image files were, I needed to split the images into smaller chunks or patches to be able to use the images for training a Convolutional Neural Network (CNN). Below is the code for this. In addition PCA is also performed on these patches to reduce the spectral dimensions of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ea46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee3318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in label files mapping the class labels to filenames\n",
    "df = pd.read_csv(r\"D:\\hyperspectral\\visnir_patches\\labels_day5.csv\")\n",
    "train_df,  test_df = train_test_split(df, test_size=0.2, stratify=df[\"class\"], random_state=42)\n",
    "train_df.to_csv(r\"D:\\hyperspectral\\visnir_patches\\train_day5_labels.csv\", index=False)\n",
    "test_df.to_csv(r\"D:\\hyperspectral\\visnir_patches\\test_day5_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172390c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_memmap_cube(path, n_bands, width, dtype=np.float32, mode=\"r\"):\n",
    "    \"\"\"\n",
    "    Function for opening .npy files as a memmap\n",
    "    \n",
    "    :param path: path to datafolder\n",
    "    :param n_bands: number of bands in the data cubes \n",
    "    :param width: the width of the data cubes \n",
    "    :param dtype: dtype of the data cube \n",
    "    :param mode: mode for opening the memmap \n",
    "    \"\"\"\n",
    "    size_bytes = os.path.getsize(path)\n",
    "    itemsize = np.dtype(dtype).itemsize\n",
    "    n_elems = size_bytes // itemsize\n",
    "\n",
    "    # number of (length * width) elements\n",
    "    if n_elems % n_bands != 0:\n",
    "        raise ValueError(\n",
    "            f\"{path}: total elements {n_elems} is not divisible by n_bands={n_bands}\"\n",
    "        )\n",
    "\n",
    "    n_spatial = n_elems // n_bands\n",
    "\n",
    "    if n_spatial % width != 0:\n",
    "        raise ValueError(\n",
    "            f\"{path}: spatial elements {n_spatial} not divisible by width={width}\"\n",
    "        )\n",
    "\n",
    "    length = n_spatial // width\n",
    "    shape = (length, width, n_bands)\n",
    "\n",
    "    return np.memmap(path, dtype=dtype, mode=mode, shape=shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patches_no_pca(csv_path, data_folder, out_path,\n",
    "                            expected_bands=673, patch_hw=(25, 25),\n",
    "                            min_nonzero_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Generate image patches from the hyperspectral image. \n",
    "    \n",
    "    :param csv_path: path to the file mapping labels to filenames\n",
    "    :param data_folder: path to the data folder \n",
    "    :param out_path: path to where the patches are stored \n",
    "    :param expected_bands: expected number of bands in the data cubes\n",
    "    :param patch_hw: patch height and width, given as a tuple (height, width)\n",
    "    :param min_nonzero_ratio: the minimum number of non-zero pixels for a patch to be saved. \n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    classes = sorted(df[\"class\"].unique())\n",
    "    class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "    # Only look in these subfolders\n",
    "    valid_days = [\"day2\", \"day5\", \"day7\", \"day9\"]\n",
    "\n",
    "    ph, pw = patch_hw\n",
    "    patches, labels, image_ids = [], [], []\n",
    "\n",
    "    for img_idx, row in df.iterrows():\n",
    "\n",
    "        # Find which folder contains this file\n",
    "        path = None\n",
    "        for d in valid_days:\n",
    "            candidate = os.path.join(data_folder, d, row[\"filename\"])\n",
    "            if os.path.exists(candidate):\n",
    "                path = candidate\n",
    "                break\n",
    "\n",
    "        if path is None:\n",
    "            print(\"File not found in any day folder:\", row[\"filename\"])\n",
    "            continue\n",
    "\n",
    "        cube = open_memmap_cube(path, n_bands=expected_bands, width=384)\n",
    "        H, W, B = cube.shape\n",
    "        if ph > H or pw > W:\n",
    "            continue\n",
    "\n",
    "        band0 = cube[..., 0]\n",
    "        nonzero_mask = band0 != 0\n",
    "\n",
    "        for top in range(0, H - ph + 1, ph):\n",
    "            for left in range(0, W - pw + 1, pw):\n",
    "                m = nonzero_mask[top:top+ph, left:left+pw]\n",
    "                if m.mean() < min_nonzero_ratio:\n",
    "                    continue\n",
    "\n",
    "                patch = cube[top:top+ph, left:left+pw, :]\n",
    "                patch = np.moveaxis(patch, -1, 0).astype(\"float32\")\n",
    "\n",
    "                patches.append(patch)\n",
    "                labels.append(class_to_idx[row[\"class\"]])\n",
    "                image_ids.append(img_idx)\n",
    "\n",
    "    patches = np.stack(patches, 0)\n",
    "    labels = np.asarray(labels, dtype=np.int64)\n",
    "    image_ids = np.asarray(image_ids, dtype=np.int32)\n",
    "\n",
    "    np.savez_compressed(out_path,\n",
    "                        patches=patches,\n",
    "                        labels=labels,\n",
    "                        image_ids=image_ids,\n",
    "                        patch_hw=patch_hw,\n",
    "                        expected_bands=expected_bands)\n",
    "\n",
    "    print(\"Saved:\", out_path, patches.shape, labels.shape, image_ids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc205b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\hyperspectral\\swir_patches\\train_patches_day9_swir.npz (339, 288, 32, 32) (339,) (339,)\n",
      "Saved: D:\\hyperspectral\\swir_patches\\test_patches_day9_swir.npz (79, 288, 32, 32) (79,) (79,)\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE\n",
    "generate_patches_no_pca(csv_path=r\"D:\\hyperspectral\\visnir_patches\\train_day5_labels.csv\", data_folder=r\"D:\\hyperspectral\\visnir\\masked_images_day5\", out_path=r\"D:\\hyperspectral\\visnir_masked\\train_patches_day5_ids.npz\",  patch_hw=(25, 25), expected_bands=673)\n",
    "generate_patches_no_pca(csv_path=r\"D:\\hyperspectral\\visnir_patches\\test_day5_labels.csv\", data_folder=r\"D:\\hyperspectral\\visnir\\masked_images_day5\",out_path=r\"D:\\hyperspectral\\visnir_masked\\test_patches_day5_ids.npz\", patch_hw=(25, 25), expected_bands=673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_pca_on_patches(npz_path, n_components=50, batch_pixels=200_000):\n",
    "    \"\"\"\n",
    "    Fits PCA on the image patches\n",
    "    \n",
    "    :param npz_path: path to the data folder with the image patches\n",
    "    :param n_components: number of principal components \n",
    "    :param batch_pixels: number of pixels to base the PCA on\n",
    "    \"\"\"\n",
    "    data = np.load(npz_path)\n",
    "    patches = data[\"patches\"]           # (N, B, ph, pw)\n",
    "    N, B, ph, pw = patches.shape\n",
    "\n",
    "    ipca = IncrementalPCA(n_components=n_components)\n",
    "\n",
    "    # iterate in chunks of patches to avoid RAM blowup\n",
    "    idx = 0\n",
    "    while idx < N:\n",
    "        end = min(idx + 64, N)         # 64 patches at a time, tune as needed\n",
    "        batch = patches[idx:end]       # (batch, B, ph, pw)\n",
    "        batch_flat = batch.reshape(-1, B)  # pixels: (batch*ph*pw, B)\n",
    "\n",
    "        # to reduce compute, you can randomly subsample rows from batch_flat\n",
    "        if batch_flat.shape[0] > batch_pixels:\n",
    "            choice = np.random.choice(batch_flat.shape[0],\n",
    "                                      size=batch_pixels, replace=False)\n",
    "            batch_flat = batch_flat[choice]\n",
    "\n",
    "        ipca.partial_fit(batch_flat)\n",
    "        idx = end\n",
    "\n",
    "    return ipca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca_to_patches(npz_in, npz_out, pca):\n",
    "    \"\"\"\n",
    "    Applies PCA to the image patches. \n",
    "    \n",
    "    :param npz_in: path to the data folder with the image patches\n",
    "    :param npz_out: path to the folder where the PCA patches is to be stored\n",
    "    :param pca: pca function \n",
    "    \"\"\"\n",
    "    i\n",
    "    data = np.load(npz_in)\n",
    "    P = data[\"patches\"]        # (N, B, ph, pw)\n",
    "    y = data[\"labels\"]         # (N,)\n",
    "    img_ids = data[\"image_ids\"]# (N,)\n",
    "    N, B, ph, pw = P.shape\n",
    "    K = pca.n_components_\n",
    "\n",
    "    Pp = np.empty((N, K, ph, pw), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        p = P[i].reshape(B, -1).T               # (ph*pw, B)\n",
    "        Pp[i] = pca.transform(p).astype(np.float32).T.reshape(K, ph, pw)\n",
    "\n",
    "    np.savez_compressed(npz_out,\n",
    "                        patches=Pp,\n",
    "                        labels=y,\n",
    "                        image_ids=img_ids,      # <-- keep ids\n",
    "                        patch_hw=(ph, pw),\n",
    "                        n_components=K)\n",
    "    print(\"Saved PCA patches:\", npz_out, Pp.shape, y.shape, img_ids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45f358da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA patches: D:\\hyperspectral\\visnir_masked\\pca_train_patches_day5_32.npz (9601, 32, 25, 25) (9601,) (9601,)\n",
      "Saved PCA patches: D:\\hyperspectral\\visnir_masked\\pca_test_patches_day5_32.npz (2754, 32, 25, 25) (2754,) (2754,)\n"
     ]
    }
   ],
   "source": [
    "pca = fit_pca_on_patches(npz_path=r\"D:\\hyperspectral\\visnir_masked\\train_patches_day5_ids.npz\", n_components=32)\n",
    "apply_pca_to_patches(npz_in=r\"D:\\hyperspectral\\visnir_masked\\train_patches_day5_ids.npz\", npz_out=r\"D:\\hyperspectral\\visnir_masked\\pca_train_patches_day5_32.npz\", pca=pca)\n",
    "apply_pca_to_patches(npz_in=r\"D:\\hyperspectral\\visnir_masked\\test_patches_day5_ids.npz\", npz_out=r\"D:\\hyperspectral\\visnir_masked\\pca_test_patches_day5_32.npz\", pca=pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b5ce2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA patches: D:\\hyperspectral\\visnir_masked\\pca_train_patches_day5_16.npz (9601, 16, 25, 25) (9601,) (9601,)\n",
      "Saved PCA patches: D:\\hyperspectral\\visnir_masked\\pca_test_patches_day5_16.npz (2754, 16, 25, 25) (2754,) (2754,)\n"
     ]
    }
   ],
   "source": [
    "pca = fit_pca_on_patches(npz_path=r\"D:\\hyperspectral\\visnir_masked\\train_patches_day5_ids.npz\", n_components=16)\n",
    "apply_pca_to_patches(npz_in=r\"D:\\hyperspectral\\visnir_masked\\train_patches_day5_ids.npz\", npz_out=r\"D:\\hyperspectral\\visnir_masked\\pca_train_patches_day5_16.npz\", pca=pca)\n",
    "apply_pca_to_patches(npz_in=r\"D:\\hyperspectral\\visnir_masked\\test_patches_day5_ids.npz\", npz_out=r\"D:\\hyperspectral\\visnir_masked\\pca_test_patches_day5_16.npz\", pca=pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
